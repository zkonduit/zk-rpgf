{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "\n",
                "from core import constants\n",
                "from core.utils import *\n",
                "\n",
                "log = get_logger()\n",
                "\n",
                "pd.set_option(\"display.float_format\", \"{:.2f}\".format)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## RPGF 3 Data Check and Cleanup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"data/dummy_data_rpgf3.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Address</th>\n",
                            "      <th>Has voted</th>\n",
                            "      <th>Has published</th>\n",
                            "      <th>Published at</th>\n",
                            "      <th>Created at</th>\n",
                            "      <th>Updated at</th>\n",
                            "      <th>Projects in ballot</th>\n",
                            "      <th>Votes</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>r1VjArnVgx</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>2023-10-14 14:43:58</td>\n",
                            "      <td>2023-11-12 05:16:37</td>\n",
                            "      <td>0</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>TP3fAbnFbm</td>\n",
                            "      <td>True</td>\n",
                            "      <td>True</td>\n",
                            "      <td>2023-11-21 02:25:59</td>\n",
                            "      <td>2023-09-03 10:16:45</td>\n",
                            "      <td>2023-11-14 10:13:01</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'amount': '147316', 'projectId': 'proj0'}]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>ogrNwwmq6O</td>\n",
                            "      <td>True</td>\n",
                            "      <td>True</td>\n",
                            "      <td>2023-11-14 04:23:37</td>\n",
                            "      <td>2023-09-05 10:46:42</td>\n",
                            "      <td>2023-11-08 15:38:00</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'amount': '897865', 'projectId': 'proj0'}]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>11</th>\n",
                            "      <td>EHS2JpDzfO</td>\n",
                            "      <td>True</td>\n",
                            "      <td>True</td>\n",
                            "      <td>2023-11-27 21:39:32</td>\n",
                            "      <td>2023-11-23 11:05:44</td>\n",
                            "      <td>2023-11-27 11:20:23</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'amount': '702474', 'projectId': 'proj0'}]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>q5QnuVdYXy</td>\n",
                            "      <td>True</td>\n",
                            "      <td>True</td>\n",
                            "      <td>2023-11-28 17:47:00</td>\n",
                            "      <td>2023-10-22 20:38:10</td>\n",
                            "      <td>2023-11-27 06:07:49</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'amount': '398887', 'projectId': 'proj0'}]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>15</th>\n",
                            "      <td>ndTdtdD5Gd</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>2023-09-19 10:29:38</td>\n",
                            "      <td>2023-10-18 05:52:23</td>\n",
                            "      <td>0</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>10</th>\n",
                            "      <td>GhnuKoneNo</td>\n",
                            "      <td>True</td>\n",
                            "      <td>True</td>\n",
                            "      <td>2023-11-26 11:18:32</td>\n",
                            "      <td>2023-11-09 05:17:29</td>\n",
                            "      <td>2023-11-16 18:52:45</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'amount': '944313', 'projectId': 'proj0'}]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>14</th>\n",
                            "      <td>dx9qWCA79I</td>\n",
                            "      <td>True</td>\n",
                            "      <td>True</td>\n",
                            "      <td>2023-11-29 12:44:31</td>\n",
                            "      <td>2023-10-10 11:00:48</td>\n",
                            "      <td>2023-11-26 14:38:21</td>\n",
                            "      <td>1</td>\n",
                            "      <td>[{'amount': '947279', 'projectId': 'proj0'}]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>12</th>\n",
                            "      <td>1dOOdTXglH</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>2023-10-10 21:56:15</td>\n",
                            "      <td>2023-11-25 06:11:01</td>\n",
                            "      <td>0</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19</th>\n",
                            "      <td>q3UjrnvQ0F</td>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>2023-11-25 06:11:02</td>\n",
                            "      <td>2023-11-26 01:44:29</td>\n",
                            "      <td>0</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       Address  Has voted  Has published         Published at  \\\n",
                            "1   r1VjArnVgx       True          False                  NaN   \n",
                            "0   TP3fAbnFbm       True           True  2023-11-21 02:25:59   \n",
                            "3   ogrNwwmq6O       True           True  2023-11-14 04:23:37   \n",
                            "11  EHS2JpDzfO       True           True  2023-11-27 21:39:32   \n",
                            "4   q5QnuVdYXy       True           True  2023-11-28 17:47:00   \n",
                            "15  ndTdtdD5Gd       True          False                  NaN   \n",
                            "10  GhnuKoneNo       True           True  2023-11-26 11:18:32   \n",
                            "14  dx9qWCA79I       True           True  2023-11-29 12:44:31   \n",
                            "12  1dOOdTXglH      False          False                  NaN   \n",
                            "19  q3UjrnvQ0F       True          False                  NaN   \n",
                            "\n",
                            "             Created at           Updated at  Projects in ballot  \\\n",
                            "1   2023-10-14 14:43:58  2023-11-12 05:16:37                   0   \n",
                            "0   2023-09-03 10:16:45  2023-11-14 10:13:01                   1   \n",
                            "3   2023-09-05 10:46:42  2023-11-08 15:38:00                   1   \n",
                            "11  2023-11-23 11:05:44  2023-11-27 11:20:23                   1   \n",
                            "4   2023-10-22 20:38:10  2023-11-27 06:07:49                   1   \n",
                            "15  2023-09-19 10:29:38  2023-10-18 05:52:23                   0   \n",
                            "10  2023-11-09 05:17:29  2023-11-16 18:52:45                   1   \n",
                            "14  2023-10-10 11:00:48  2023-11-26 14:38:21                   1   \n",
                            "12  2023-10-10 21:56:15  2023-11-25 06:11:01                   0   \n",
                            "19  2023-11-25 06:11:02  2023-11-26 01:44:29                   0   \n",
                            "\n",
                            "                                           Votes  \n",
                            "1                                             []  \n",
                            "0   [{'amount': '147316', 'projectId': 'proj0'}]  \n",
                            "3   [{'amount': '897865', 'projectId': 'proj0'}]  \n",
                            "11  [{'amount': '702474', 'projectId': 'proj0'}]  \n",
                            "4   [{'amount': '398887', 'projectId': 'proj0'}]  \n",
                            "15                                            []  \n",
                            "10  [{'amount': '944313', 'projectId': 'proj0'}]  \n",
                            "14  [{'amount': '947279', 'projectId': 'proj0'}]  \n",
                            "12                                            []  \n",
                            "19                                            []  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "display(df.sample(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-01-03 03:49:12 INFO | Check - Num Ballots: 20\n",
                        "2024-01-03 03:49:12 INFO | Check - Num Submissions (Published): 12\n",
                        "2024-01-03 03:49:12 INFO | Check - Address is unique.\n",
                        "2024-01-03 03:49:12 INFO | Check - 2 voters out of 20 have not voted.\n",
                        "2024-01-03 03:49:12 INFO | Check - 8 voters out of 20 have not published.\n"
                    ]
                }
            ],
            "source": [
                "log.info(\"Check - Num Ballots: \" + str(df[\"Has published\"].count()))\n",
                "log.info(\"Check - Num Submissions (Published): \" + str(df[\"Has published\"].sum()))\n",
                "\n",
                "# Check if voter_address is unique\n",
                "if df[\"Address\"].nunique() == df.shape[0]:\n",
                "    log.info(\"Check - Address is unique.\")\n",
                "else:\n",
                "    diff = df.shape[0] - df[\"Address\"].nunique()\n",
                "    log.info(f\"Check - Address is not unique. There are {diff} duplicates.\")\n",
                "\n",
                "# Check if all voters have voted\n",
                "if df[df[\"Has voted\"] == False].shape[0] > 0:\n",
                "    not_voted = df[df[\"Has voted\"] == False].shape[0]\n",
                "    total = df[\"Address\"].nunique()\n",
                "    log.info(f\"Check - {not_voted} voters out of {total} have not voted.\")\n",
                "else:\n",
                "    log.info(\"Check - All voters have voted.\")\n",
                "\n",
                "# Check if all voters have published\n",
                "if df[df[\"Has published\"] == False].shape[0] > 0:\n",
                "    not_voted = df[df[\"Has published\"] == False].shape[0]\n",
                "    total = df[\"Address\"].nunique()\n",
                "    log.info(f\"Check - {not_voted} voters out of {total} have not published.\")\n",
                "else:\n",
                "    log.info(\"Check - All voters have published.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply the function and concatenate results\n",
                "expanded_list = [\n",
                "    expand_json(safe_json_loads(row), idx) for idx, row in df[\"Votes\"].items()\n",
                "]\n",
                "expanded_df = pd.concat(expanded_list, ignore_index=True)\n",
                "\n",
                "result_df = expanded_df.set_index(\"original_index\").join(df.set_index(df.index))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Num Projects Voted : 0\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>amount</th>\n",
                            "      <th>projectId</th>\n",
                            "      <th>Address</th>\n",
                            "      <th>Has voted</th>\n",
                            "      <th>Has published</th>\n",
                            "      <th>Published at</th>\n",
                            "      <th>Created at</th>\n",
                            "      <th>Updated at</th>\n",
                            "      <th>Projects in ballot</th>\n",
                            "      <th>Votes</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>original_index</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "Empty DataFrame\n",
                            "Columns: [amount, projectId, Address, Has voted, Has published, Published at, Created at, Updated at, Projects in ballot, Votes]\n",
                            "Index: []"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "testing_address = \"zgdSu8Yr87\"\n",
                "print_df = result_df[result_df[\"Address\"] == testing_address]\n",
                "print(\"Num Projects Voted : \" + str(print_df[\"projectId\"].count()))\n",
                "display(print_df.head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "columns = [col for col in result_df.columns if col not in [\"amount\", \"projectId\"]]\n",
                "columns += [\"amount\", \"projectId\"]  # Add the columns to the end of the list\n",
                "result_df = result_df[columns]\n",
                "\n",
                "# Update df columns names\n",
                "result_df.columns = [\n",
                "    \"voter_address\",\n",
                "    \"has_voted\",\n",
                "    \"has_published\",\n",
                "    \"published_at\",\n",
                "    \"created_at\",\n",
                "    \"updated_at\",\n",
                "    \"projects_in_ballot\",\n",
                "    \"votes\",\n",
                "    \"amount\",\n",
                "    \"project_id\",\n",
                "]\n",
                "\n",
                "result_df.drop(columns=\"votes\", inplace=True)\n",
                "\n",
                "result_df[\"amount\"] = pd.to_numeric(result_df[\"amount\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>voter_address</th>\n",
                            "      <th>has_voted</th>\n",
                            "      <th>has_published</th>\n",
                            "      <th>published_at</th>\n",
                            "      <th>created_at</th>\n",
                            "      <th>updated_at</th>\n",
                            "      <th>projects_in_ballot</th>\n",
                            "      <th>amount</th>\n",
                            "      <th>project_id</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>original_index</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "Empty DataFrame\n",
                            "Columns: [voter_address, has_voted, has_published, published_at, created_at, updated_at, projects_in_ballot, amount, project_id]\n",
                            "Index: []"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# result_df.head()\n",
                "result_df[result_df[\"voter_address\"] == testing_address].head(70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Calculate Voting Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "allocator = ProjectAllocator(\n",
                "    total_amount=constants.TOTAL_AMOUNT,\n",
                "    min_amount=constants.MIN_AMOUNT,\n",
                "    quorum=constants.QUORUM,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "initial_allocation = allocator.calculate_initial_allocation(result_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "Cannot take a larger sample than population when 'replace=False'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[1;32m/Users/alexandercamuto/Documents/GitHub/zk-rpgf/rpgf3_allocator.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alexandercamuto/Documents/GitHub/zk-rpgf/rpgf3_allocator.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m display(initial_allocation\u001b[39m.\u001b[39;49msample(\u001b[39m10\u001b[39;49m))\n",
                        "File \u001b[0;32m~/Documents/GitHub/zk-rpgf/.env/lib/python3.9/site-packages/pandas/core/generic.py:6029\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6026\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   6027\u001b[0m     weights \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39mpreprocess_weights(\u001b[39mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 6029\u001b[0m sampled_indices \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39;49msample(obj_len, size, replace, weights, rs)\n\u001b[1;32m   6030\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(sampled_indices, axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m   6032\u001b[0m \u001b[39mif\u001b[39;00m ignore_index:\n",
                        "File \u001b[0;32m~/Documents/GitHub/zk-rpgf/.env/lib/python3.9/site-packages/pandas/core/sample.py:152\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid weights: weights sum to zero\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m \u001b[39mreturn\u001b[39;00m random_state\u001b[39m.\u001b[39;49mchoice(obj_len, size\u001b[39m=\u001b[39;49msize, replace\u001b[39m=\u001b[39;49mreplace, p\u001b[39m=\u001b[39;49mweights)\u001b[39m.\u001b[39mastype(\n\u001b[1;32m    153\u001b[0m     np\u001b[39m.\u001b[39mintp, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m )\n",
                        "File \u001b[0;32mnumpy/random/mtrand.pyx:1000\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
                    ]
                }
            ],
            "source": [
                "display(initial_allocation.sample(5))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scaling the total to 30M OP by project and filter out those with < 1500 OP\n",
                "allocation_iter = initial_allocation[initial_allocation[\"is_eligible\"] == True].copy()\n",
                "allocation_iter[\"scaled_amount\"] = allocation_iter[\"median_amount\"]\n",
                "# display(allocation_iter)\n",
                "# Set a maximum number of iterations to prevent infinite loop\n",
                "max_iterations = 10\n",
                "current_iteration = 0\n",
                "\n",
                "while (\n",
                "    allocation_iter[\"scaled_amount\"].sum() != constants.TOTAL_AMOUNT\n",
                "    and current_iteration <= max_iterations\n",
                "):\n",
                "    allocation_iter = allocator.scale_allocations_oneby(allocation_iter)\n",
                "    current_iteration += 1\n",
                "\n",
                "    log.info(\"Check - Current iteration: \" + str(current_iteration))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check if the loop exited due to reaching max iterations\n",
                "if (\n",
                "    current_iteration == max_iterations\n",
                "    and allocation_iter[\"scaled_amount\"].sum() != constants.TOTAL_AMOUNT\n",
                "):\n",
                "    log.info(\"Maximum iterations reached without meeting the total amount condition.\")\n",
                "else:\n",
                "    final_total = allocation_iter[\"scaled_amount\"].sum()\n",
                "    log.info(\n",
                "        f\"Condition met with {final_total} OP allocated through {current_iteration} iteration(s).\"\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# join the initial allocation with the final allocation, if scaled_amount is null then make it 0\n",
                "final_allocation = initial_allocation.merge(\n",
                "    allocation_iter[\"scaled_amount\"],\n",
                "    how=\"left\",\n",
                "    on=\"project_id\",\n",
                ").fillna({\"scaled_amount\": 0})\n",
                "\n",
                "# check if the final allocation table still contains all projects.\n",
                "if final_allocation.index.nunique() == result_df[\"project_id\"].nunique():\n",
                "    log.info(\"Check - Final allocation table has included all the projects.\")\n",
                "else:\n",
                "    log.info(\n",
                "        \"Check - Final allocation table has missing projects. Printing out the missing projects below.\"\n",
                "    )\n",
                "    log.info(\n",
                "        result_df[~result_df[\"project_id\"].isin(final_allocation.index)][\"project_id\"]\n",
                "    )\n",
                "\n",
                "# check if the final allocation table still sums to the total amount.\n",
                "if final_allocation[\"scaled_amount\"].sum() == final_total:\n",
                "    log.info(\n",
                "        \"Check - Final allocation table sums to the right amount of OP: \"\n",
                "        + str(final_total)\n",
                "    )\n",
                "else:\n",
                "    log.info(\n",
                "        \"Check - Final allocation table does not sum to the total OP. Printing out the missing amount below.\"\n",
                "    )\n",
                "    log.info(str(final_total - final_allocation[\"scaled_amount\"].sum()) + \" OP\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# export csv\n",
                "# allocation_iter.drop(columns=\"median_amount\", inplace=True)\n",
                "final_allocation.to_csv(\"data/rpgf3_allocation_final.csv\")\n",
                "\n",
                "log.info(f\"Results saved in data/rpgf3_allocation_final.csv.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_allocation.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "to_cut = (\n",
                "    allocation_iter[allocation_iter[\"scaled_amount\"] < 1500]\n",
                "    .sort_values(by=\"scaled_amount\")\n",
                "    .head(1)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check if to_cut is empty\n",
                "to_cut.empty"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Calculate Voting Results using pytorch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "result_tensor, num_projects = allocator.convert_df_to_tensor(result_df)\n",
                "project_tensors = allocator.get_project_tensor(result_tensor, num_projects)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# export to onnx\n",
                "allocator.eval()\n",
                "\n",
                "# convert projects tensors to tuple\n",
                "final_allocation_torch = allocator.forward(*project_tensors)\n",
                "final_allocation.shape\n",
                "\n",
                "input_names = ['input_' + str(i) for i in range(len(project_tensors))]\n",
                "    # Export the model\n",
                "torch.onnx.export(allocator,               # model being run\n",
                "                      tuple(project_tensors),          # model input (or a tuple for multiple inputs)\n",
                "                      \"network.onnx\",           # where to save the model (can be a file or file-like object)\n",
                "                      export_params=False,       # store the trained parameter weights inside the model file\n",
                "                      opset_version=17,         # the ONNX version to export the model to\n",
                "                      do_constant_folding=True, # whether to execute constant folding for optimization\n",
                "                      input_names = input_names,   # the model's input names\n",
                "                      output_names = ['output'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now include sanity checks for the data. We will check the following:\n",
                "- that the pandas and pytorch dataframes are the same\n",
                "- that the median and scaled median allocations are the same\n",
                "- that eligibility is the same"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# a bunch of code to compare pytorch output and the pandas output as a sanity check\n",
                "final_allocation_torch_np = final_allocation_torch.detach().numpy()\n",
                "final_allocation_torch_df = pd.DataFrame(final_allocation_torch_np, columns=[\"votes_count\", \"median_amount\", \"is_eligible\", \"scaled_amount\"])\n",
                "# convert is eligible to boolean\n",
                "final_allocation_torch_df[\"is_eligible\"] = final_allocation_torch_df[\"is_eligible\"].astype(bool)\n",
                "# convert votes count to int\n",
                "final_allocation_torch_df[\"votes_count\"] = final_allocation_torch_df[\"votes_count\"].astype(int)\n",
                "# add index project_id\n",
                "final_allocation_torch_df = final_allocation_torch_df.set_index(final_allocation.index.sort_values())\n",
                "\n",
                "# sorted vy project id\n",
                "final_allocation_torch_df = final_allocation_torch_df.sort_index()\n",
                "# sort final allocation by project id\n",
                "final_allocation_sorted = final_allocation.sort_index()\n",
                "\n",
                "display(final_allocation_torch_df.head(10))\n",
                "display(final_allocation_sorted.head(10))\n",
                "# compare the two outputs\n",
                "print(\"Are the two outputs equal?\")\n",
                "final_allocation_torch_df.compare(final_allocation_sorted)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After which we can proceed to generate the settings file for `ezkl` and run calibrate settings to find the optimal settings for `ezkl`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ezkl\n",
                "import os\n",
                "\n",
                "model_path = \"network.onnx\"\n",
                "settings_path = \"settings.json\"\n",
                "compiled_model_path = os.path.join('network.compiled')\n",
                "pk_path = os.path.join('test.pk')\n",
                "vk_path = os.path.join('test.vk')\n",
                "settings_path = os.path.join('settings.json')\n",
                "\n",
                "witness_path = os.path.join('witness.json')\n",
                "data_path = os.path.join('input.json')\n",
                "\n",
                "py_run_args = ezkl.PyRunArgs()\n",
                "py_run_args.input_visibility = \"public\"\n",
                "py_run_args.output_visibility = \"public\"\n",
                "py_run_args.param_visibility = \"fixed\" # private by default\n",
                "\n",
                "res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We calibrate the settings to finetune the circuit to the data. This is done by running the `calibrate_settings` function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = os.path.join(\"input.json\")\n",
                "\n",
                "data = dict(input_data = [tensor.detach().numpy().reshape([-1]).tolist() for tensor in project_tensors])\n",
                "\n",
                "# Serialize data into file:\n",
                "json.dump(data, open(data_path, 'w'))\n",
                "\n",
                "\n",
                "ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load settings and shrink run_args.logrows by 1 to allow for lookup overflow\n",
                "settings = json.load(open(settings_path, 'r'))\n",
                "settings['run_args']['logrows'] += 1\n",
                "# now save\n",
                "json.dump(settings, open(settings_path, 'w'))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we will compile the model. The compilation step allow us to generate proofs faster."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Before we can setup the circuit params, we need a SRS (Structured Reference String). The SRS is used to generate the proofs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# srs path\n",
                "res = ezkl.get_srs( settings_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# now generate the witness file \n",
                "\n",
                "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
                "assert os.path.isfile(witness_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now run setup, this will generate a proving key (pk) and verification key (vk). The proving key is used for proving while the verification key is used for verificaton."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# setup\n",
                "res = ezkl.setup(\n",
                "        compiled_model_path,\n",
                "        vk_path,\n",
                "        pk_path,\n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "assert os.path.isfile(vk_path)\n",
                "assert os.path.isfile(pk_path)\n",
                "assert os.path.isfile(settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GENERATE A PROOF\n",
                "\n",
                "\n",
                "proof_path = os.path.join('test.pf')\n",
                "\n",
                "res = ezkl.prove(\n",
                "        witness_path,\n",
                "        compiled_model_path,\n",
                "        pk_path,\n",
                "        proof_path,\n",
                "        \"single\",\n",
                "    )\n",
                "\n",
                "print(res)\n",
                "assert os.path.isfile(proof_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now verify the proof. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VERIFY IT\n",
                "\n",
                "res = ezkl.verify(\n",
                "        proof_path,\n",
                "        settings_path,\n",
                "        vk_path,\n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "print(\"verified\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now create an EVM / `.sol` verifier that can be deployed on chain to verify submitted proofs using a view function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "abi_path = 'test.abi'\n",
                "sol_code_path = 'test_1.sol'\n",
                "\n",
                "res = ezkl.create_evm_verifier(\n",
                "        vk_path,\n",
                "        settings_path,\n",
                "        sol_code_path,\n",
                "        abi_path,\n",
                "    )\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Deploying the Verifier\n",
                "Now that we have the circuit setup, we can proceed to deploy the verifier onchain.\n",
                "\n",
                "We will need to setup `solc=0.8.20` for this."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check if notebook is in colab\n",
                "try:\n",
                "    import subprocess\n",
                "    import sys\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"solc-select\"])\n",
                "    !solc-select install 0.8.20\n",
                "    !solc-select use 0.8.20\n",
                "    !solc --version\n",
                "\n",
                "# rely on local installation if the notebook is not in colab\n",
                "except:\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "onchain_input_array = []\n",
                "\n",
                "proof = json.load(open(proof_path, 'r'))\n",
                "\n",
                "# using a loop\n",
                "# avoiding printing last comma\n",
                "formatted_output = \"[\"\n",
                "for i, value in enumerate(proof[\"instances\"]):\n",
                "    for j, field_element in enumerate(value):\n",
                "        onchain_input_array.append(ezkl.vecu64_to_felt(field_element))\n",
                "        formatted_output += str(onchain_input_array[-1])\n",
                "        if j != len(value) - 1:\n",
                "            formatted_output += \", \"\n",
                "    formatted_output += \"]\"\n",
                "\n",
                "# This will be the values you use onchain\n",
                "# copy them over to remix and see if they verify\n",
                "# What happens when you change a value?\n",
                "print(\"pubInputs: \", formatted_output)\n",
                "print(\"proof: \", \"0x\" + proof[\"proof\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sanity checks on circuit outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install onnxruntime plotly"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import onnx\n",
                "import onnxruntime\n",
                "import os\n",
                "import json\n",
                "import ezkl\n",
                "import numpy as np\n",
                "\n",
                "witness_path = os.path.join('witness.json')\n",
                "settings_path = os.path.join('settings.json')\n",
                "model_path = os.path.join('network.onnx')\n",
                "data_path = os.path.join('input.json')\n",
                "\n",
                "def get_ezkl_output(witness_file, settings_file):\n",
                "    # convert the quantized ezkl output to float value\n",
                "    witness_output = json.load(open(witness_file))\n",
                "    outputs = witness_output['outputs']\n",
                "    with open(settings_file) as f:\n",
                "        settings = json.load(f)\n",
                "    ezkl_outputs = [[ezkl.vecu64_to_float(\n",
                "        outputs[i][j], settings['model_output_scales'][i]) for j in range(len(outputs[i]))] for i in range(len(outputs))]\n",
                "    return ezkl_outputs\n",
                "\n",
                "\n",
                "def get_onnx_output(model_file, input_file):\n",
                "    # generate the ML model output from the ONNX file\n",
                "    onnx_model = onnx.load(model_file)\n",
                "    onnx.checker.check_model(onnx_model)\n",
                "\n",
                "    with open(input_file) as f:\n",
                "        inputs = json.load(f)\n",
                "    # reshape the input to the model\n",
                "    num_inputs = len(inputs['input_data'])\n",
                "\n",
                "    onnx_input = dict()\n",
                "    for i in range(num_inputs):\n",
                "        input_node = onnx_model.graph.input[i]\n",
                "        dims = []\n",
                "        elem_type = input_node.type.tensor_type.elem_type\n",
                "        for dim in input_node.type.tensor_type.shape.dim:\n",
                "            if dim.dim_value == 0:\n",
                "                dims.append(1)\n",
                "            else:\n",
                "                dims.append(dim.dim_value)\n",
                "        if elem_type == 7:\n",
                "            inputs_onnx = np.array(inputs['input_data'][i]).astype(\n",
                "                np.int64).reshape(dims)\n",
                "        elif elem_type == 9:\n",
                "            inputs_onnx = np.array(inputs['input_data'][i]).astype(\n",
                "                bool).reshape(dims)\n",
                "        else:\n",
                "            inputs_onnx = np.array(inputs['input_data'][i]).astype(\n",
                "                np.float32).reshape(dims)\n",
                "        onnx_input[input_node.name] = inputs_onnx\n",
                "    try:\n",
                "        onnx_session = onnxruntime.InferenceSession(model_file)\n",
                "        onnx_output = onnx_session.run(None, onnx_input)\n",
                "    except Exception as e:\n",
                "        print(\"Error in ONNX runtime: \", e)\n",
                "        print(\"using inputs[output_data]\")\n",
                "        onnx_output = inputs['output_data']\n",
                "    return onnx_output[0]\n",
                "\n",
                "\n",
                "def compare_outputs(zk_output, onnx_output):\n",
                "    # calculate hamming difference between the 2 outputs (which are lists)\n",
                "\n",
                "    res = []\n",
                "    \n",
                "    print(\"zk_output\", zk_output)\n",
                "    print(\"onnx_output\", onnx_output)\n",
                "\n",
                "    contains_sublist = any(isinstance(sub, list) for sub in zk_output)\n",
                "    if contains_sublist:\n",
                "        try:\n",
                "            if len(onnx_output) == 1:\n",
                "                zk_output = zk_output[0]\n",
                "        except Exception as e:\n",
                "            zk_output = zk_output[0]\n",
                "\n",
                "    zip_object = zip(np.array(zk_output).flatten(),\n",
                "                     np.array(onnx_output).flatten())\n",
                "    for list1_i, list2_i in zip_object:\n",
                "        if list1_i == 0.0 and list2_i == 0.0:\n",
                "            res.append(0)\n",
                "        else:\n",
                "            diff = list1_i - list2_i\n",
                "            res.append(diff)\n",
                "\n",
                "\n",
                "    return np.abs(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import plotly.express as px\n",
                "import pandas as pd\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "    # get the ezkl output\n",
                "ezkl_output = get_ezkl_output(witness_path, settings_path)\n",
                "    # get the onnx output\n",
                "onnx_output = get_onnx_output(model_path, data_path)\n",
                "    # compare the outputs\n",
                "l1_difference = compare_outputs(ezkl_output, onnx_output)\n",
                "\n",
                "df = pd.DataFrame(l1_difference, columns=[\"hamming distance\"])\n",
                "\n",
                "\n",
                "# Create a histogram\n",
                "fig = px.histogram(df, x=\"hamming distance\",\n",
                "                  title=\"Distribution of hamming distance\")\n",
                "fig.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "analytics-internal-nXLXwD2Z",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.15"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
